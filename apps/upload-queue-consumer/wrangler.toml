name = "upload-queue-consumer"
main = "src/index.ts"
compatibility_date = "2025-01-13"
compatibility_flags = ["nodejs_compat"]

############################
# Default (PRODUCTION) ENV #
############################

# Queue Consumer – reads messages from the main parse-cv queue
[[queues.consumers]]
queue = "parse-cv"
max_batch_size = 10
max_batch_timeout = 5
max_retries = 3
dead_letter_queue = "parse-cv-dlq"

# Queue Producer – used by your worker to send messages to the DLQ
[[queues.producers]]
binding = "PARSE_CV_DLQ"
queue = "parse-cv-dlq"

# R2 Bucket binding
# - bucket_name is used in production deploys
# - preview_bucket_name is used by `wrangler dev` (preview)
[[r2_buckets]]
binding = "UPLOADS_BUCKET"
bucket_name = "prod"
preview_bucket_name = "dev"
remote = true

# Non-secret vars (secrets still via `wrangler secret put`)
[vars]
ENVIRONMENT = "prod"
API_URL = "https://api.yourapp.com"  # Update with your production API URL
AXIOM_OTEL_DATASET = "otel-upload-queue-consumer"  # OpenTelemetry traces dataset
AXIOM_LOGS_DATASET = "upload-queue-consumer"  # Regular logs/events dataset
# AI Model Configuration
AI_MODEL_NAME = "gpt-4o-mini"
AI_MODEL_INPUT_PRICE_PER_1M = "0.15"  # $0.15 per 1M input tokens
AI_MODEL_OUTPUT_PRICE_PER_1M = "0.60"  # $0.60 per 1M output tokens

[observability]
[observability.logs]
enabled = true
head_sampling_rate = 1
invocation_logs = true
persist = true

##############
# DEV ENV    #
##############

[env.dev]
name = "upload-queue-consumer-dev"

# Dev-specific queues (completely separate from prod)
[[env.dev.queues.consumers]]
queue = "parse-cv-dev"
max_batch_size = 10
max_batch_timeout = 5
max_retries = 3
dead_letter_queue = "parse-cv-dlq-dev"

[[env.dev.queues.producers]]
binding = "PARSE_CV_DLQ"
queue = "parse-cv-dlq-dev"

# Dev R2 bucket
[[env.dev.r2_buckets]]
binding = "UPLOADS_BUCKET"
bucket_name = "dev"
preview_bucket_name = "dev"
remote = true

[env.dev.vars]
ENVIRONMENT = "dev"
API_URL = "https://lazzyapply-api-dev.onrender.com"
AXIOM_OTEL_DATASET = "otel-upload-queue-consumer"  # OpenTelemetry traces dataset
AXIOM_LOGS_DATASET = "upload-queue-consumer"  # Regular logs/events dataset
# AI Model Configuration
AI_MODEL_NAME = "gpt-4o-mini"
AI_MODEL_INPUT_PRICE_PER_1M = "0.15"  # $0.80 per 1M input tokens
AI_MODEL_OUTPUT_PRICE_PER_1M = "0.60"  # $3.20 per 1M output tokens

################
# LOCAL ENV    #
################

[env.local]
name = "upload-queue-consumer-local"

# Local-specific queues (completely separate from dev/prod)
[[env.local.queues.consumers]]
queue = "parse-cv-local"
max_batch_size = 10
max_batch_timeout = 5
max_retries = 3
dead_letter_queue = "parse-cv-dlq-local"

[[env.local.queues.producers]]
binding = "PARSE_CV_DLQ"
queue = "parse-cv-dlq-local"

# Local R2 bucket (connects to remote R2 bucket for development)
[[env.local.r2_buckets]]
binding = "UPLOADS_BUCKET"
bucket_name = "local"
preview_bucket_name = "local"
remote = true

[env.local.vars]
ENVIRONMENT = "local"
API_URL = "http://0.0.0.0:5050"
AXIOM_OTEL_DATASET = "otel-upload-queue-consumer"  # OpenTelemetry traces dataset
AXIOM_LOGS_DATASET = "upload-queue-consumer"  # Regular logs/events dataset
# AI Model Configuration
AI_MODEL_NAME = "gpt-4o-mini"
AI_MODEL_INPUT_PRICE_PER_1M = "0.15"  # $0.15 per 1M input tokens
AI_MODEL_OUTPUT_PRICE_PER_1M = "0.60"  # $0.60 per 1M output tokens
